{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caso seja necessária a instalação de bibliotecas\n",
    "# #pip install sty bibtexparser pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas necessárias\n",
    "import bibtexparser\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estrutura de controle\n",
    "chaves=list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções\n",
    "def parser_bibtex(file_bib):\n",
    "    with open(file_bib,encoding='utf-8') as bibtex_file:\n",
    "        try:\n",
    "            bib_database = bibtexparser.load(bibtex_file)\n",
    "            return pd.DataFrame(bib_database.entries)\n",
    "        except:\n",
    "            print('Falha no arquivo', file_bib)\n",
    "            return pd.DataFrame(None)\n",
    "def drop_invalid(df_tmp):\n",
    "    for x in range(len(df_tmp)-1,-1,-1):\n",
    "        if((df_tmp.loc[x].loc['ID'])[:8] == 'NoAuthor'):\n",
    "            df_tmp.drop([int(x)], inplace=True)\n",
    "        elif(df_tmp.loc[x].loc['author'] == ''):\n",
    "            df_tmp.drop([int(x)], inplace=True)\n",
    "    df_tmp.reset_index(inplace=True,drop=True)\n",
    "    return df_tmp,len(df_tmp)\n",
    "    \n",
    "def drop_not_doi(df_tmp):\n",
    "    for x in range(len(df_tmp)-1,-1,-1):\n",
    "        if((df_tmp.loc[x].loc['doi']) == ''):\n",
    "            df_tmp.drop([int(x)], inplace=True)\n",
    "    df_tmp.reset_index(inplace=True,drop=True)\n",
    "    return df_tmp,len(df_tmp)\n",
    "\n",
    "def drop_year(df_tmp,ano):\n",
    "    for x in range(len(df_tmp)-1,-1,-1):\n",
    "        if(int(df_tmp.loc[x].loc['year']) < ano):\n",
    "            df_tmp.drop([int(x)], inplace=True)\n",
    "    df_tmp.reset_index(inplace=True,drop=True)\n",
    "    return df_tmp,len(df_tmp)\n",
    "\n",
    "def drop_pag(df_tmp,pag):\n",
    "    for x in range(len(df_tmp)-1,-1,-1):\n",
    "        #print(df_tmp.loc[x].loc['pages'])\n",
    "        z = (str(df_tmp.loc[x].loc['pages'])).split('-')\n",
    "        if(len(z) == 4):\n",
    "            w=int(z[3])-int(z[1])\n",
    "        elif(len(z) == 2):\n",
    "            if((z[1].isnumeric())and(z[0].isnumeric())):\n",
    "                w=int(z[1])-int(z[0])\n",
    "            else:\n",
    "                w=0\n",
    "        else:\n",
    "            w=pag+1\n",
    "        if(w < 4):\n",
    "            df_tmp.drop([int(x)], inplace=True)\n",
    "    df_tmp.reset_index(inplace=True,drop=True)\n",
    "    return df_tmp,len(df_tmp)\n",
    "\n",
    "def drop_source(df_tmp,entrada,tipo):\n",
    "    for x in range(len(df_tmp)-1,-1,-1):\n",
    "        try:\n",
    "            if(df_tmp.loc[x].loc['ENTRYTYPE'] in entrada):\n",
    "                df_tmp.drop([int(x)], inplace=True)\n",
    "            elif(df_tmp.loc[x].loc['document_type'] in tipo):\n",
    "                df_tmp.drop([int(x)], inplace=True)\n",
    "        except:\n",
    "            None\n",
    "    df_tmp.reset_index(inplace=True,drop=True)\n",
    "    return df_tmp,len(df_tmp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definidas as chaves de busca:\n",
    "\n",
    "1. critical infrastructure AND (vulnerabilit* AND (analys* OR Assessment OR characterization OR scan* OR tool)) AND (threat AND (shar* OR intelligent))\n",
    "1. network AND (Security OR ``Vulnerabilit* Tool'' OR scan*) AND shar* AND (threat OR risk OR intelligent OR information) AND risk AND (Classification OR reduction OR mitigation)\n",
    "1. threat AND (shar* OR intelligent) AND test AND (intrusion OR penetration)\n",
    "1. cyber AND security AND assessment AND threat AND vulnerabilit*\n",
    "\n",
    "Extraiu-se as referências dos resultados da busca (Export) em arquivos [base]-[chave]_[página].bib\n",
    "\n",
    "Aplicação dos Critérios de Elegibilidade, que podem ser avaliados objetivamente com os dados da referência.\n",
    "\n",
    "Aplicação de demais Critérios e Seleção de Estudos:\n",
    "-  Utiliza Inteligência de Ameaças?\n",
    "-  Identifica ou avalia vulnerabilidades?\n",
    "-  Utiliza orquestração de ferramentas?\n",
    "-  Utiliza automatização de processos? \n",
    "-  Mitiga vulnerabilidades em redes? \n",
    "-  Atua com medidas preventivas em Segurança Cibernética?\n",
    "-  Possui relacionamento com Infraestrutura Crítica?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerar Dataframe dos arquivos gerados nas Bases de busca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar arquivos\n",
    "y=0\n",
    "for x in os.listdir():\n",
    "    if('.bib' in x):\n",
    "        chaves.append(['df_' + x.split(\".\")[0].replace('-','_')])\n",
    "        globals()[chaves[y][0]] = parser_bibtex(x)\n",
    "        chaves[y].append(len(globals()[chaves[y][0]]))\n",
    "        y+=1\n",
    "del x,y\n",
    "chaves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicar Critérios de Elegibilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrada Inválida\n",
    "for y,chave in enumerate(chaves):\n",
    "    globals()[chave[0]],aux = drop_invalid(globals()[chave[0]])\n",
    "    chaves[y].append(aux)\n",
    "del aux,y\n",
    "chaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ano\n",
    "ano=2010\n",
    "for y,chave in enumerate(chaves):\n",
    "    globals()[chave[0]],aux = drop_year(globals()[chave[0]],ano)\n",
    "    chaves[y].append(aux)\n",
    "del aux,y\n",
    "chaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de páginas\n",
    "pag = 3\n",
    "for y,chave in enumerate(chaves):\n",
    "    globals()[chave[0]],aux = drop_pag(globals()[chave[0]],pag)\n",
    "    chaves[y].append(aux)\n",
    "del aux,y\n",
    "chaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Não indexado\n",
    "for y,chave in enumerate(chaves):\n",
    "    globals()[chave[0]],aux = drop_not_doi(globals()[chave[0]])\n",
    "    chaves[y].append(aux)\n",
    "del aux,y\n",
    "chaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonte\n",
    "entrada = ['book','inbook']\n",
    "tipo = ['Book Chapter','Article in Press','Note']\n",
    "for y,chave in enumerate(chaves):\n",
    "    globals()[chave[0]],aux = drop_source(globals()[chave[0]],entrada,tipo)\n",
    "    chaves[y].append(aux)\n",
    "del aux,y\n",
    "chaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar por Base de Conhecimento e Remover Duplicatas\n",
    "df_ieee = pd.DataFrame(None)\n",
    "df_scopus = pd.DataFrame(None)\n",
    "for y,chave in enumerate(chaves):\n",
    "    if('ieee' in chave[0]):\n",
    "        df_ieee = pd.concat([df_ieee,globals()[chave[0]]], ignore_index=True)\n",
    "    elif(('scopus')in chave[0]):\n",
    "        df_scopus = pd.concat([df_scopus,globals()[chave[0]]], ignore_index=True)\n",
    "    del globals()[chave[0]]\n",
    "bases = [['df_ieee',len(df_ieee)],['df_scopus',len(df_scopus)]]\n",
    "for y,base in enumerate(bases):\n",
    "    globals()[base[0]].drop_duplicates(subset=['ID','title'],inplace=True)\n",
    "    globals()[base[0]].reset_index(inplace=True,drop=True)\n",
    "    bases[y].append(len(globals()[base[0]]))\n",
    "    \n",
    "del y\n",
    "bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar por Base de Conhecimento e Remover Duplicatas\n",
    "df = pd.concat([df_ieee,df_scopus], ignore_index=True)\n",
    "pesquisa=['dados',len(df)]\n",
    "df.drop_duplicates(subset=['doi','title'],inplace=True)\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "pesquisa.append(len(df))\n",
    "\n",
    "del df_ieee,df_scopus\n",
    "pesquisa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relatório de aplicação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerar Referências padrão ITA para implementação no LATEX"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Lista de exemplos de Referências a serem incorporadas no arquivo referencias.bib do LATEX.\n",
    "* Alguns campos são opcionais outros obrigatórios! * \n",
    "\n",
    "@article{Alladi2019,\n",
    " author = {Alladi, Tejasvi and Chamola, Vinay and Parizi, Reza M. and Choo, Kim-Kwang Raymond},\n",
    " doi = {10.1109/ACCESS.2019.2956748},\n",
    " editor = {},\n",
    " journal = {IEEE Access},\n",
    " month = {},\n",
    " number = {},\n",
    " pages = {176935--176951},\n",
    " title = {{Blockchain Applications for Industry 4.0 and Industrial IoT: A Review}},\n",
    " url = {https://ieeexplore.ieee.org/document/8917991/},\n",
    " volume = {7},\n",
    " year = {2019}\n",
    "}\n",
    "\n",
    "@book{ABNT2015,\n",
    " address = {Rio de Janeiro},\n",
    " author = {ABNT},\n",
    " booktitle = {},\n",
    " edition = {},\n",
    " isbn = {},\n",
    " pages = {},\n",
    " publisher = {ABNT},\n",
    " subtitle = {},\n",
    " title = {{ABNT NBR ISO/IEC 27032:2015 Diretrizes para seguran{\\c{c}}a cibern{\\'{e}}tica}},\n",
    " url = {},\n",
    " volume = {},\n",
    " year = {2015}\n",
    "}\n",
    "\n",
    "@inproceedings{Aarya2018,\n",
    " address = {},\n",
    " author = {Aarya, P.S and Rajan, Akhila and Sachin, K.P.S and Gopi, Reshma and Sreenu, G},\n",
    " conference-location = {},\n",
    " conference-number = {},\n",
    " conference-year = {},\n",
    " organization = {},\n",
    " pages = {123--128},\n",
    " publisher = {IEEE},\n",
    " subtitle = {},\n",
    " title = {{Web Scanning: Existing Techniques and Future}},\n",
    " url = {https://ieeexplore.ieee.org/document/8662934/},\n",
    " year = {2018}\n",
    "}\n",
    "\n",
    "@lei{glossarioSIC2019, \n",
    " address = {Brasília, DF},\n",
    " journal = {Diário Oficial da União},\n",
    " month = {27 set.},\n",
    " organization = {Brasil},\n",
    " volume = {Seção 1},\n",
    " title = {{Portaria nº 93, de 26 de setembro de 2019. Aprova o Glossário de Segurança da Informação}},\n",
    " number = {190},\n",
    " pages = {3},\n",
    " url = {http://www.in.gov.br/en/web/dou/-/portaria-n-93-de-26-de-setembro-de-2019-219115663},\n",
    " urlaccessdate = {23 mar. 2020},\n",
    " year = {2019}\n",
    "}\n",
    "\n",
    "@mastersthesis{Martins2018,\n",
    " author = {Martins, James de Castro},\n",
    " pages = {123},\n",
    " title = {{MAVARS - Um M{\\'{e}}todo {\\'{A}}gil Para Valida{\\c{c}}{\\~{a}}o de Requisitos de Seguran{\\c{c}}a}},\n",
    " year = {2018},\n",
    " year-presented = {2018},\n",
    " type = {Mestrado em Engenharia Eletrônica e Computação},\n",
    " publisher = {ITA},\n",
    " school = {Instituto Tecnol{\\'{o}}gico de Aeron{\\'{a}}utica},\n",
    " address = {S{\\~{a}}o Jos{\\'{e}} dos Campos}\n",
    "}\n",
    "\n",
    "@misc{Adinolfi2017,\n",
    " address = {},\n",
    " author = {Adinolfi, Daniel and Singleton, Anthony},\n",
    " edition = {},\n",
    " note = {},\n",
    " publisher = {},\n",
    " subtitle = {},\n",
    " title = {{CVE IDs and How to Get Them}},\n",
    " url = {https://cve.mitre.org/CVEIDsAndHowToGetThem.pdf},\n",
    " urlaccessdate = {13 jun. 2020},\n",
    " volume = {},\n",
    " year = {2017}\n",
    "}\n",
    "\n",
    "@techreport{Caralli2007,\n",
    " address = {Pittsburgh, PA, USA},\n",
    " author = {Caralli, Richard a Richard a. Caralli and Stevens, James F. and Young, Lisa R. and Wilson, William R.},\n",
    " booktitle = {},\n",
    " edition = {},\n",
    " isbn = {},\n",
    " pages = {1--113},\n",
    " publisher = {},\n",
    " subtitle = {},\n",
    " title = {{Introducing OCTAVE Allegro: Improving the Information Security Risk Assessment Process}},\n",
    " url = {},\n",
    " volume = {},\n",
    " year = {2007}\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = {\n",
    "    'article': ['ENTRYTYPE','ID','year', 'pages', 'volume', 'journal', 'title','author'],\n",
    "    'book': ['ENTRYTYPE','ID','year','pages', 'volume', 'title',\n",
    "       'author', 'ENTRYTYPE', 'ID', 'url', 'publisher', 'issn',\n",
    "       'isbn', 'address', 'booktitle'],\n",
    "    'inproceedings': ['ENTRYTYPE','ID','address','author','conference-location','conference-number','conference-year',\n",
    "        'organization','pages','publisher','subtitle','title','url','year'],\n",
    "    'lei': ['ENTRYTYPE','ID','address','journal','month','organization','volume','title','number','pages','url','urlaccessdate','year'],\n",
    "    'mastersthesis': ['ENTRYTYPE','ID','author', 'pages', 'title', 'year', 'year-presented', 'type', 'publisher', 'school', 'address'],\n",
    "    'misc': ['ENTRYTYPE','ID','address','author','edition','note','publisher','subtitle','title','url','urlaccessdate','volume','year'],\n",
    "    'techreport': ['ENTRYTYPE','ID','address','author','booktitle','edition','isbn','pages','publisher','subtitle','title','url','volume','year']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bibtexparser.bwriter import BibTexWriter\n",
    "from bibtexparser.bibdatabase import BibDatabase\n",
    "\n",
    "writer = BibTexWriter()\n",
    "writer.indent = ' '     # indent entries with 4 spaces instead of one\n",
    "writer.comma_first = False  # place the comma at the beginning of the line\n",
    "\n",
    "for entry in (dados.keys()):\n",
    "    globals()['df_' + entry] = df.loc[(entry == df['ENTRYTYPE'])].drop(columns=['abstract','keywords'],axis=1)\n",
    "    globals()['df_' + entry].reset_index(inplace=True,drop=True)\n",
    "    globals()['df_' + entry] = globals()['df_' + entry].replace(np.nan, '', regex=True)\n",
    "    globals()[entry] = globals()['df_' + entry].to_dict(orient=\"records\")\n",
    "    globals()['db_' + entry] = BibDatabase()\n",
    "    globals()['db_' + entry].entries = globals()[entry]\n",
    "\n",
    "    with open('referencias.bib', 'a',encoding='utf-8') as bibfile:\n",
    "        bibfile.write(writer.write(globals()['db_' + entry]))\n",
    "    \n",
    "    del globals()['df_' + entry], globals()['db_' + entry],globals()[entry]\n",
    "del writer, bibfile"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Busca pelo DOI [em implementação, rascunho]\n",
    "for x in range(0,len(da)):\n",
    "    if(da.loc[x].loc['doi'] == ''):\n",
    "        print('N')\n",
    "    else:\n",
    "        response = requests.get('http://dx.doi.org/'+da.loc[x].loc['doi'], headers=headers)\n",
    "        bib_database = bibtexparser.loads(response.text)\n",
    "        dr = pd.concat([dr,pd.DataFrame.from_dict(bib_database.entries)], ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c347c8f9a7ef94e4c9e03b4513be7835ed18f45b99a2a817fb579f408b867b16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
