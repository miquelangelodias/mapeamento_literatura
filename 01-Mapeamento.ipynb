{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caso seja necessária a instalação de bibliotecas\n",
    "# #pip install sty bibtexparser pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas necessárias\n",
    "import bibtexparser\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estrutura de controle\n",
    "chaves=list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções\n",
    "def parser_bibtex(file_bib):\n",
    "    with open(file_bib,encoding='utf-8') as bibtex_file:\n",
    "        try:\n",
    "            bib_database = bibtexparser.load(bibtex_file)\n",
    "            return pd.DataFrame(bib_database.entries)\n",
    "        except:\n",
    "            print('Falha no arquivo', file_bib)\n",
    "            return pd.DataFrame(None)\n",
    "def drop_invalid(df_tmp):\n",
    "    for x in range(len(df_tmp)-1,-1,-1):\n",
    "        if((df_tmp.loc[x].loc['ID'])[:8] == 'NoAuthor'):\n",
    "            df_tmp.drop([int(x)], inplace=True)\n",
    "        elif(df_tmp.loc[x].loc['author'] == ''):\n",
    "            df_tmp.drop([int(x)], inplace=True)\n",
    "    df_tmp.reset_index(inplace=True,drop=True)\n",
    "    return df_tmp,len(df_tmp)\n",
    "    \n",
    "def drop_not_doi(df_tmp):\n",
    "    for x in range(len(df_tmp)-1,-1,-1):\n",
    "        if((df_tmp.loc[x].loc['doi']) == ''):\n",
    "            df_tmp.drop([int(x)], inplace=True)\n",
    "    df_tmp.reset_index(inplace=True,drop=True)\n",
    "    return df_tmp,len(df_tmp)\n",
    "\n",
    "def drop_year(df_tmp,ano):\n",
    "    for x in range(len(df_tmp)-1,-1,-1):\n",
    "        if(int(df_tmp.loc[x].loc['year']) < ano):\n",
    "            df_tmp.drop([int(x)], inplace=True)\n",
    "    df_tmp.reset_index(inplace=True,drop=True)\n",
    "    return df_tmp,len(df_tmp)\n",
    "\n",
    "def drop_pag(df_tmp,pag):\n",
    "    for x in range(len(df_tmp)-1,-1,-1):\n",
    "        #print(df_tmp.loc[x].loc['pages'])\n",
    "        z = (str(df_tmp.loc[x].loc['pages'])).split('-')\n",
    "        if(len(z) == 4):\n",
    "            w=int(z[3])-int(z[1])\n",
    "        elif(len(z) == 2):\n",
    "            if((z[1].isnumeric())and(z[0].isnumeric())):\n",
    "                w=int(z[1])-int(z[0])\n",
    "            else:\n",
    "                w=0\n",
    "        else:\n",
    "            w=pag+1\n",
    "        if(w < 4):\n",
    "            df_tmp.drop([int(x)], inplace=True)\n",
    "    df_tmp.reset_index(inplace=True,drop=True)\n",
    "    return df_tmp,len(df_tmp)\n",
    "\n",
    "def drop_source(df_tmp,entrada,tipo):\n",
    "    for x in range(len(df_tmp)-1,-1,-1):\n",
    "        try:\n",
    "            if(df_tmp.loc[x].loc['ENTRYTYPE'] in entrada):\n",
    "                df_tmp.drop([int(x)], inplace=True)\n",
    "            elif(df_tmp.loc[x].loc['document_type'] in tipo):\n",
    "                df_tmp.drop([int(x)], inplace=True)\n",
    "        except:\n",
    "            None\n",
    "    df_tmp.reset_index(inplace=True,drop=True)\n",
    "    return df_tmp,len(df_tmp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definidas as chaves de busca:\n",
    "\n",
    "1. critical infrastructure AND (vulnerabilit* AND (analys* OR Assessment OR characterization OR scan* OR tool)) AND (threat AND (shar* OR intelligent))\n",
    "1. network AND (Security OR ``Vulnerabilit* Tool'' OR scan*) AND shar* AND (threat OR risk OR intelligent OR information) AND risk AND (Classification OR reduction OR mitigation)\n",
    "1. threat AND (shar* OR intelligent) AND test AND (intrusion OR penetration)\n",
    "1. cyber AND security AND assessment AND threat AND vulnerabilit*\n",
    "\n",
    "Extraiu-se as referências dos resultados da busca (Export) em arquivos [base]-[chave]_[página].bib\n",
    "\n",
    "Aplicação dos Critérios de Elegibilidade, que podem ser avaliados objetivamente com os dados da referência.\n",
    "\n",
    "Aplicação de demais Critérios e Seleção de Estudos:\n",
    "-  Utiliza Inteligência de Ameaças?\n",
    "-  Identifica ou avalia vulnerabilidades?\n",
    "-  Utiliza orquestração de ferramentas?\n",
    "-  Utiliza automatização de processos? \n",
    "-  Mitiga vulnerabilidades em redes? \n",
    "-  Atua com medidas preventivas em Segurança Cibernética?\n",
    "-  Possui relacionamento com Infraestrutura Crítica?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerar Dataframe dos arquivos gerados nas Bases de busca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar arquivos\n",
    "y=0\n",
    "for x in os.listdir():\n",
    "    if('.bib' in x):\n",
    "        chaves.append(['df_' + x.split(\".\")[0].replace('-','_')])\n",
    "        globals()[chaves[y][0]] = parser_bibtex(x)\n",
    "        chaves[y].append(len(globals()[chaves[y][0]]))\n",
    "        y+=1\n",
    "del x,y\n",
    "chaves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicar Critérios de Elegibilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrada Inválida\n",
    "for y,chave in enumerate(chaves):\n",
    "    globals()[chave[0]],aux = drop_invalid(globals()[chave[0]])\n",
    "    chaves[y].append(aux)\n",
    "del aux,y\n",
    "chaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ano\n",
    "ano=2010\n",
    "for y,chave in enumerate(chaves):\n",
    "    globals()[chave[0]],aux = drop_year(globals()[chave[0]],ano)\n",
    "    chaves[y].append(aux)\n",
    "del aux,y\n",
    "chaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de páginas\n",
    "pag = 3\n",
    "for y,chave in enumerate(chaves):\n",
    "    globals()[chave[0]],aux = drop_pag(globals()[chave[0]],pag)\n",
    "    chaves[y].append(aux)\n",
    "del aux,y\n",
    "chaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Não indexado\n",
    "for y,chave in enumerate(chaves):\n",
    "    globals()[chave[0]],aux = drop_not_doi(globals()[chave[0]])\n",
    "    chaves[y].append(aux)\n",
    "del aux,y\n",
    "chaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonte\n",
    "entrada = ['book','inbook']\n",
    "tipo = ['Book Chapter','Article in Press','Note']\n",
    "for y,chave in enumerate(chaves):\n",
    "    globals()[chave[0]],aux = drop_source(globals()[chave[0]],entrada,tipo)\n",
    "    chaves[y].append(aux)\n",
    "del aux,y\n",
    "chaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar por Base de Conhecimento e Remover Duplicatas\n",
    "df_ieee = pd.DataFrame(None)\n",
    "df_scopus = pd.DataFrame(None)\n",
    "for y,chave in enumerate(chaves):\n",
    "    if('ieee' in chave[0]):\n",
    "        df_ieee = pd.concat([df_ieee,globals()[chave[0]]], ignore_index=True)\n",
    "    elif(('scopus')in chave[0]):\n",
    "        df_scopus = pd.concat([df_scopus,globals()[chave[0]]], ignore_index=True)\n",
    "    del globals()[chave[0]]\n",
    "bases = [['df_ieee',len(df_ieee)],['df_scopus',len(df_scopus)]]\n",
    "for y,base in enumerate(bases):\n",
    "    globals()[base[0]].drop_duplicates(subset=['ID','title'],inplace=True)\n",
    "    globals()[base[0]].reset_index(inplace=True,drop=True)\n",
    "    bases[y].append(len(globals()[base[0]]))\n",
    "    \n",
    "del y\n",
    "bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar por Base de Conhecimento e Remover Duplicatas\n",
    "df = pd.concat([df_ieee,df_scopus], ignore_index=True)\n",
    "pesquisa=['dados',len(df)]\n",
    "df.drop_duplicates(subset=['doi','title'],inplace=True)\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "pesquisa.append(len(df))\n",
    "\n",
    "del df_ieee,df_scopus\n",
    "pesquisa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relatório de aplicação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerar Referências padrão ITA para implementação no LATEX"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Lista de exemplos de Referências a serem incorporadas no arquivo referencias.bib do LATEX.\n",
    "* Alguns campos são opcionais outros obrigatórios! * \n",
    "\n",
    "@article{Alladi2019,\n",
    " author = {Alladi, Tejasvi and Chamola, Vinay and Parizi, Reza M. and Choo, Kim-Kwang Raymond},\n",
    " doi = {10.1109/ACCESS.2019.2956748},\n",
    " editor = {},\n",
    " journal = {IEEE Access},\n",
    " month = {},\n",
    " number = {},\n",
    " pages = {176935--176951},\n",
    " title = {{Blockchain Applications for Industry 4.0 and Industrial IoT: A Review}},\n",
    " url = {https://ieeexplore.ieee.org/document/8917991/},\n",
    " volume = {7},\n",
    " year = {2019}\n",
    "}\n",
    "\n",
    "@book{ABNT2015,\n",
    " address = {Rio de Janeiro},\n",
    " author = {ABNT},\n",
    " booktitle = {},\n",
    " edition = {},\n",
    " isbn = {},\n",
    " pages = {},\n",
    " publisher = {ABNT},\n",
    " subtitle = {},\n",
    " title = {{ABNT NBR ISO/IEC 27032:2015 Diretrizes para seguran{\\c{c}}a cibern{\\'{e}}tica}},\n",
    " url = {},\n",
    " volume = {},\n",
    " year = {2015}\n",
    "}\n",
    "\n",
    "@inproceedings{Aarya2018,\n",
    " address = {},\n",
    " author = {Aarya, P.S and Rajan, Akhila and Sachin, K.P.S and Gopi, Reshma and Sreenu, G},\n",
    " conference-location = {},\n",
    " conference-number = {},\n",
    " conference-year = {},\n",
    " organization = {},\n",
    " pages = {123--128},\n",
    " publisher = {IEEE},\n",
    " subtitle = {},\n",
    " title = {{Web Scanning: Existing Techniques and Future}},\n",
    " url = {https://ieeexplore.ieee.org/document/8662934/},\n",
    " year = {2018}\n",
    "}\n",
    "\n",
    "@lei{glossarioSIC2019, \n",
    " address = {Brasília, DF},\n",
    " journal = {Diário Oficial da União},\n",
    " month = {27 set.},\n",
    " organization = {Brasil},\n",
    " volume = {Seção 1},\n",
    " title = {{Portaria nº 93, de 26 de setembro de 2019. Aprova o Glossário de Segurança da Informação}},\n",
    " number = {190},\n",
    " pages = {3},\n",
    " url = {http://www.in.gov.br/en/web/dou/-/portaria-n-93-de-26-de-setembro-de-2019-219115663},\n",
    " urlaccessdate = {23 mar. 2020},\n",
    " year = {2019}\n",
    "}\n",
    "\n",
    "@mastersthesis{Martins2018,\n",
    " author = {Martins, James de Castro},\n",
    " pages = {123},\n",
    " title = {{MAVARS - Um M{\\'{e}}todo {\\'{A}}gil Para Valida{\\c{c}}{\\~{a}}o de Requisitos de Seguran{\\c{c}}a}},\n",
    " year = {2018},\n",
    " year-presented = {2018},\n",
    " type = {Mestrado em Engenharia Eletrônica e Computação},\n",
    " publisher = {ITA},\n",
    " school = {Instituto Tecnol{\\'{o}}gico de Aeron{\\'{a}}utica},\n",
    " address = {S{\\~{a}}o Jos{\\'{e}} dos Campos}\n",
    "}\n",
    "\n",
    "@misc{Adinolfi2017,\n",
    " address = {},\n",
    " author = {Adinolfi, Daniel and Singleton, Anthony},\n",
    " edition = {},\n",
    " note = {},\n",
    " publisher = {},\n",
    " subtitle = {},\n",
    " title = {{CVE IDs and How to Get Them}},\n",
    " url = {https://cve.mitre.org/CVEIDsAndHowToGetThem.pdf},\n",
    " urlaccessdate = {13 jun. 2020},\n",
    " volume = {},\n",
    " year = {2017}\n",
    "}\n",
    "\n",
    "@techreport{Caralli2007,\n",
    " address = {Pittsburgh, PA, USA},\n",
    " author = {Caralli, Richard a Richard a. Caralli and Stevens, James F. and Young, Lisa R. and Wilson, William R.},\n",
    " booktitle = {},\n",
    " edition = {},\n",
    " isbn = {},\n",
    " pages = {1--113},\n",
    " publisher = {},\n",
    " subtitle = {},\n",
    " title = {{Introducing OCTAVE Allegro: Improving the Information Security Risk Assessment Process}},\n",
    " url = {},\n",
    " volume = {},\n",
    " year = {2007}\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = {\n",
    "    'article': ['ENTRYTYPE','ID','year', 'pages', 'volume', 'journal', 'title','author'],\n",
    "    'book': ['ENTRYTYPE','ID','year','pages', 'volume', 'title',\n",
    "       'author', 'ENTRYTYPE', 'ID', 'url', 'publisher', 'issn',\n",
    "       'isbn', 'address', 'booktitle'],\n",
    "    'inproceedings': ['ENTRYTYPE','ID','address','author','conference-location','conference-number','conference-year',\n",
    "        'organization','pages','publisher','subtitle','title','url','year'],\n",
    "    'lei': ['ENTRYTYPE','ID','address','journal','month','organization','volume','title','number','pages','url','urlaccessdate','year'],\n",
    "    'mastersthesis': ['ENTRYTYPE','ID','author', 'pages', 'title', 'year', 'year-presented', 'type', 'publisher', 'school', 'address'],\n",
    "    'misc': ['ENTRYTYPE','ID','address','author','edition','note','publisher','subtitle','title','url','urlaccessdate','volume','year'],\n",
    "    'techreport': ['ENTRYTYPE','ID','address','author','booktitle','edition','isbn','pages','publisher','subtitle','title','url','volume','year']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bibtexparser.bwriter import BibTexWriter\n",
    "from bibtexparser.bibdatabase import BibDatabase\n",
    "\n",
    "writer = BibTexWriter()\n",
    "writer.indent = ' '     # indent entries with 4 spaces instead of one\n",
    "writer.comma_first = False  # place the comma at the beginning of the line\n",
    "\n",
    "for entry in (dados.keys()):\n",
    "    globals()['df_' + entry] = df.loc[(entry == df['ENTRYTYPE'])].drop(columns=['abstract','keywords'],axis=1)\n",
    "    globals()['df_' + entry].reset_index(inplace=True,drop=True)\n",
    "    globals()['df_' + entry] = globals()['df_' + entry].replace(np.nan, '', regex=True)\n",
    "    globals()[entry] = globals()['df_' + entry].to_dict(orient=\"records\")\n",
    "    globals()['db_' + entry] = BibDatabase()\n",
    "    globals()['db_' + entry].entries = globals()[entry]\n",
    "\n",
    "    if(entry == 'inproceedings'):\n",
    "        #resolver conferência\n",
    "        #remover journal\n",
    "    with open('referencias.bib', 'a',encoding='utf-8') as bibfile:\n",
    "        bibfile.write(writer.write(globals()['db_' + entry]))\n",
    "    \n",
    "#    del globals()['df_' + entry], globals()['db_' + entry],globals()[entry]\n",
    "#del writer, bibfile"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Busca pelo DOI [em implementação, rascunho]\n",
    "for x in range(0,len(da)):\n",
    "    if(da.loc[x].loc['doi'] == ''):\n",
    "        print('N')\n",
    "    else:\n",
    "        response = requests.get('http://dx.doi.org/'+da.loc[x].loc['doi'], headers=headers)\n",
    "        bib_database = bibtexparser.loads(response.text)\n",
    "        dr = pd.concat([dr,pd.DataFrame.from_dict(bib_database.entries)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "doi_headers = {'Accept': 'text/bibliography; style=bibtex'}\n",
    "doi = '10.23919/CYCON.2019.8756895'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_doi(doi):\n",
    "    try:\n",
    "        response = requests.get('http://dx.doi.org/'+doi, headers=doi_headers)\n",
    "        bib_database = bibtexparser.loads(response.text)\n",
    "        return pd.DataFrame.from_dict(bib_database.entries)\n",
    "    except:\n",
    "        print(doi,'\\tOcorreu um erro ao pesquisar!')\n",
    "\n",
    "\n",
    "#['ENTRYTYPE','ID','address','author','conference-location','conference-number','conference-year',\n",
    "#     'organization','pages','publisher','subtitle','title','url','year']\n",
    "#def inp(doi):\n",
    "response = requests.get('http://dx.doi.org/'+doi, headers=doi_headers)\n",
    "df = pd.DataFrame.from_dict(bibtexparser.loads(response.text).entries)\n",
    "y=df.loc[0]['journal']\n",
    "x = []\n",
    "x.extend([y.split(' ')[0],y.split(' ')[1]])\n",
    "x.append(y.split(x[0]+' '+x[1]+' ')[1])\n",
    "x\n",
    "    #return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp(doi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('http://dx.doi.org/'+doi, headers=doi_headers)\n",
    "bib_database = bibtexparser.loads(response.text)\n",
    "pd.DataFrame.from_dict(bib_database.entries)\n",
    "#'article': ['ENTRYTYPE','ID','year', 'pages', 'volume', 'journal', 'title','author']\n",
    "#info_doi(doi)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "@INPROCEEDINGS{8756895,\n",
    "author={D. {Kapellmann} and R. {Washburn}},\n",
    "booktitle={2019 11th International Conference on Cyber Conflict (CyCon)}, \n",
    "title={Call to Action: Mobilizing Community Discussion to Improve Information-Sharing About Vulnerabilities in Industrial Control Systems and Critical Infrastructure},\n",
    "year={2019},\n",
    "volume={900},\n",
    "number={},\n",
    "pages={1-23},\n",
    "abstract={Vulnerability management remains a significant challenge for organizations that handle critical infrastructure worldwide. Hallmark cyber-physical incidents with disruptive and destructive capabilities like Stuxnet (2010) and Triton (2017) have exploited known vulnerabilities in information technology (IT) and operational technology (OT) assets throughout the attack lifecycle. However, the global critical infrastructure security community is still nascent in the field of industrial control systems (ICS) vulnerability management, especially in information-sharing. While their counterparts in IT security have spent years elaborating multiple resources to track and disseminate information about known vulnerabilities, the ICS community lacks specialized mechanisms for knowledge-sharing. Multiple challenges exist when addressing this issue: a general lack of awareness about ICS cybersecurity, the need to consider multiple industry sectors and unique network architectures, and the need to find a balance between protecting and releasing sensitive information regarding critical infrastructure organizations or proprietary vendor knowledge. Through a multiphase research initiative based on the user-centered design process, we intend to test and evaluate the feasibility and effectiveness of various information-sharing platform designs for streamlining the discussion of ICS vulnerabilities. In the first phase of this research, we surveyed ICS and critical infrastructure security stakeholders to gain insight into the range of cogent, shared, and divergent views of the community relating to the need for specialized resources to share information about ICS vulnerabilities. We then evaluated what these different perspectives imply for the adoption and success of certain information-sharing platform frameworks. Finally, utilizing these insights, we demonstrated possible alternative paths forward for addressing the challenge of sharing information about ICS vulnerabilities to keep critical infrastructure safe.},\n",
    "keywords={critical infrastructures;industrial control;security of data;mobilizing community discussion;industrial control systems;vulnerability management;information technology;operational technology assets;global critical infrastructure security community;knowledge-sharing;ICS cybersecurity;sensitive information;critical infrastructure organizations;information-sharing platform designs;ICS vulnerabilities;critical infrastructure security stakeholders;critical infrastructure;Hallmark cyber-physical incidents;Integrated circuits;Critical infrastructure;Organizations;Computer security;Standards organizations;Industrial control;Vulnerability management;critical infrastructure;industrial control systems (ICS);norms and standards;cyber-physical;information-sharing},\n",
    "doi={10.23919/CYCON.2019.8756895},\n",
    "ISSN={2325-5374},\n",
    "month={May}\n",
    "}\n",
    "\n",
    "@article{2019, \n",
    "title={Call to Action: Mobilizing Community Discussion to Improve Information-Sharing About Vulnerabilities in Industrial Control Systems and Critical Infrastructure}, \n",
    "url={http://dx.doi.org/10.23919/CYCON.2019.8756895}, \n",
    "DOI={10.23919/cycon.2019.8756895}, \n",
    "journal={2019 11th International Conference on Cyber Conflict (CyCon)}, \n",
    "publisher={IEEE}, \n",
    "author={Kapellmann, Daniel and Washburn, Rhyner}, \n",
    "year={2019}, \n",
    "month={May} }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c347c8f9a7ef94e4c9e03b4513be7835ed18f45b99a2a817fb579f408b867b16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
